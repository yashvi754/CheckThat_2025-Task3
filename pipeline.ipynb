{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a422d0b",
   "metadata": {},
   "source": [
    "# Claim Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1174e0",
   "metadata": {},
   "source": [
    "## My Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffff4739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run on 1 claims using qwen2.5:7b...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Claims: 100%|██████████| 1/1 [01:40<00:00, 100.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done! Processed 1 claims. Saved to 'questions_decomposed_my_prompt.json'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import ollama\n",
    "from tqdm import tqdm\n",
    "\n",
    "INPUT_FILE = 'data\\filtered_claims.json'\n",
    "OUTPUT_FILE = 'data\\questions_decomposed_my_prompt.json'\n",
    "MODEL_NAME = \"deepseek-r1:32b\"\n",
    "# MODEL_NAME = \"qwen2.5:7b\"\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "# Role\n",
    "You are an expert fact-checker. Your task is \"Claim Decomposition.\" You will receive a list of claims with metadata. For each claim, you must generate exactly 3 sub-questions that, if answered, would verify the truthfulness of the claim.\n",
    "\n",
    "# Input Format\n",
    "A JSON list of objects containing the claim and available metadata (date/country).\n",
    "\n",
    "# Output Format\n",
    "Provide a strictly valid JSON response containing a list of objects. Each object must correspond to the input claims in the exact same order.\n",
    "Use the following schema:\n",
    "[\n",
    "  {\n",
    "    \"claim\": \"The original claim text\",\n",
    "    \"questions\": [\n",
    "      \"Question 1\",\n",
    "      \"Question 2\",\n",
    "      \"Question 3\"\n",
    "    ]\n",
    "  }\n",
    "]\n",
    "\n",
    "# Instructions\n",
    "1.  **Analyze the Claim:** Identify the specific entities (who/what), the action (what happened), and the exact values or predicates (how much/details).\n",
    "    * Metadata Usage: If there are any ambiguities in the claim that can be clarified using the provided metadata, use that information, like `crawled_date` or `country_of_origin`. (e.g., \"this year\" -> specific year).\n",
    "2.  **Formulate Verification Questions:** Create 3 questions that verify the factual accuracy of these components.\n",
    "    * Numerical Precision: If the claim contains a specific number, quantity, or ranking (e.g., \"3000 crores\", \"1%\", \"5th largest\"), ensure questions verify those figures.\n",
    "    * Decompose the Predicate: If the claim implies a legal or definitions-based contradiction (e.g., \"Underage marriage\"), ensure one question verifies the definitions/laws and another verifies the actual event.\n",
    "\n",
    "# Strict Constraints\n",
    "* **Self-Containment:** Every question must be fully understandable without the original claim. Replace all pronouns (e.g., \"he,\" \"it,\" \"the bill,\" \"the year\") with the specific full names and entities provided in the text.\n",
    "* **Metadata-Grounded Entity Resolution:** Use only the entities and figures found in the claim. Do not introduce external names or laws. However, you MUST resolve relative time and location phrases (e.g., \"today,\" \"this country\") into absolute terms (e.g., \"March 7, 2024,\" \"India\") using the provided `crawled_date` and `country_of_origin`.\n",
    "* **Verification Intent:** Focus on the factual truth of the event or figure. Frame questions to ask if the facts are true (e.g., \"Did X occur?\") rather than asking what the text \"says\" or \"claims.\"\n",
    "\n",
    "# Examples\n",
    "\n",
    "## Example 1\n",
    "Input:\n",
    "{\n",
    "  \"claim\": \"The Mayor of Paris was fined 90,000 euros for breaching gender parity staffing rules in 2020.\",\n",
    "  \"crawled_date\": \"2020-12-16\",\n",
    "  \"country_of_origin\": \"france\"\n",
    "}\n",
    "Generated Questions:\n",
    "1. \"Was the Mayor of Paris fined exactly 90,000 euros in the year 2020?\"\n",
    "2. \"Was the fine against the Mayor of Paris issued specifically for a breach of gender parity staffing rules?\"\n",
    "3. \"Are there official records from 2020 confirming a 90,000 euro fine against the Mayor of Paris related to staffing regulations?\"\n",
    "\n",
    "## Example 2\n",
    "Input:\n",
    "{\n",
    "    \"claim\": \"As per today's news, farmers are protesting all over country against the increase of tax rates from 4% to 5%.\",\n",
    "    \"crawled_date\": \"2024-03-07\",\n",
    "    \"country_of_origin\": \"india\" \n",
    "}\n",
    "Generated Questions:\n",
    "1. \"Are there reports from March 7, 2024, regarding farmers in India protesting against an increase in tax rates from 4% to 5%?\"\n",
    "2. \"Is there evidence of nationwide farmer protests occurring in India in March 2024, specifically regarding tax rate changes?\"\n",
    "3. \"Are there official reports stating the increase in tax rates from 4% to 5% for farmers as of March 2024?\"\n",
    "\n",
    "# Task\n",
    "Now, process the following input JSON and output ONLY the JSON response:\n",
    "\"\"\"\n",
    "\n",
    "def process_claim_test(claim_data):\n",
    "    try:\n",
    "        response = ollama.chat(model=MODEL_NAME, messages=[\n",
    "            {'role': 'system', 'content': SYSTEM_PROMPT},\n",
    "            {'role': 'user', 'content': f\"Process this claim: {json.dumps(claim_data)}\"}\n",
    "        ], format='json')\n",
    "\n",
    "        return json.loads(response['message']['content'])\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing claim: {e}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        with open(INPUT_FILE, 'r', encoding='utf-8') as f:\n",
    "            all_claims = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Could not find '{INPUT_FILE}'. Please check the file name.\")\n",
    "        return\n",
    "\n",
    "    TEST_LIMIT = len(all_claims)\n",
    "    # TEST_LIMIT = 10\n",
    "  \n",
    "    claims_to_process = all_claims[:TEST_LIMIT]\n",
    "    results = []\n",
    "\n",
    "    print(f\"Starting run on {len(claims_to_process)} claims using {MODEL_NAME}...\")\n",
    "\n",
    "    for claim in tqdm(claims_to_process, desc=\"Processing Claims\"):\n",
    "        result = process_claim_test(claim)\n",
    "        \n",
    "        if result:\n",
    "            results.append(result)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:\n",
    "        json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"\\nDone! Processed {len(results)} claims. Saved to '{OUTPUT_FILE}'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42502090",
   "metadata": {},
   "source": [
    "## LIS Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7c1fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run on 10 claims using qwen2.5:7b...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Claims: 100%|██████████| 10/10 [05:09<00:00, 30.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done! Processed 10 claims. Saved to 'questions_decomposed_LIS_prompt.json'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import ollama\n",
    "from tqdm import tqdm\n",
    "\n",
    "INPUT_FILE = 'data\\filtered_claims.json'\n",
    "OUTPUT_FILE = 'data\\questions_decomposed_LIS_prompt.json'\n",
    "MODEL_NAME = \"deepseek-r1:32b\"\n",
    "# MODEL_NAME = \"qwen2.5:7b\"\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "# Role\n",
    "You are an expert fact-checker. Your task is \"Claim Decomposition.\"\n",
    "\n",
    "# Input Format\n",
    "A JSON list of objects containing the claim and available metadata (date/country).\n",
    "\n",
    "# Output Format\n",
    "Provide a strictly valid JSON response containing a list of objects. Each object must correspond to the input claims in the exact same order.\n",
    "Use the following schema:\n",
    "[\n",
    "  {\n",
    "    \"claim\": \"The original claim text\",\n",
    "    \"questions\": [\n",
    "      \"Question 1\",\n",
    "      \"Question 2\",\n",
    "      \"Question 3\"\n",
    "    ]\n",
    "  }\n",
    "]\n",
    "\n",
    "# Instructions\n",
    "You are a fact-checker. Your general motivation is to verify a given claim. You are at the beginning of the fact-checking process, meaning you have just received the claim, optionally with some additional\n",
    "metadata (such as the date of the claim or the author), if available. Your task now is to prepare the fact-check. That means:\n",
    "1. Begin with an interpretation of the claim. As part of the interpretation, list the key points of the claim as a list of reformulated sub-claims.\n",
    "2. Then, analyze what information is missing.\n",
    "3. Finally, present a complete, numbered list of EXACTLY 3 questions: These are questions that explore the truthfulness of the claim and that we need to answer in order to factually verify the claim.\n",
    "\n",
    "IMPORTANT:\n",
    "Follow these rules:\n",
    "* Do not use external knowledge. Use ONLY the information provided in the claim text to formulate the entities in the question.\n",
    "* Phrase each question so that it can be understood independently and without additional context. Be explicit and do not use pronouns or generic terms in place of names or objects.\n",
    "* STOP after generating the 3rd question.\n",
    "\n",
    "# Examples\n",
    "Claim: \"The new Food Bill in New Zealand bans gardening\"\n",
    "Good Question: \"Did the New Zealand government pass a food bill that restricted gardening activities for its citizens?\"\n",
    "Bad Question: \"Did the government pass a bill?\"\n",
    "Bad Question: \"Did the bill restrict activities?\"\n",
    "\n",
    "# Task\n",
    "Now, process the following input JSON and output ONLY the JSON response:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def process_claim_test(claim_data):\n",
    "    try:\n",
    "        response = ollama.chat(model=MODEL_NAME, messages=[\n",
    "            {'role': 'system', 'content': SYSTEM_PROMPT},\n",
    "            {'role': 'user', 'content': f\"Process this claim: {json.dumps(claim_data)}\"}\n",
    "        ], format='json')\n",
    "\n",
    "        return json.loads(response['message']['content'])\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing claim: {e}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        with open(INPUT_FILE, 'r', encoding='utf-8') as f:\n",
    "            all_claims = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Could not find '{INPUT_FILE}'. Please check the file name.\")\n",
    "        return\n",
    "\n",
    "    TEST_LIMIT = len(all_claims)\n",
    "    # TEST_LIMIT = 10  \n",
    "      \n",
    "    claims_to_process = all_claims[:TEST_LIMIT]\n",
    "    results = []\n",
    "\n",
    "    print(f\"Starting run on {len(claims_to_process)} claims using {MODEL_NAME}...\")\n",
    "\n",
    "    for claim in tqdm(claims_to_process, desc=\"Processing Claims\"):\n",
    "        result = process_claim_test(claim)\n",
    "        \n",
    "        if result:\n",
    "            results.append(result)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:\n",
    "        json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"\\nDone! Processed {len(results)} claims. Saved to '{OUTPUT_FILE}'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65aad7a2",
   "metadata": {},
   "source": [
    "# Build indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3995e299",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import bm25s\n",
    "from Stemmer import Stemmer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "## Configuration\n",
    "\n",
    "CORPUS_FILE = Path(\"data/corpus_evidence_unified.json\")\n",
    "INDEX_DIR = Path(\"indexes\")\n",
    "\n",
    "INDEX_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "SPARSE_INDEX_PATH = INDEX_DIR / \"bm25s_index\"\n",
    "DENSE_INDEX_PATH = INDEX_DIR / \"faiss_index.bin\"\n",
    "DOC_IDS_PATH = INDEX_DIR / \"doc_ids.json\"\n",
    "\n",
    "DENSE_MODEL = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "\n",
    "## Load and preprocess corpus\n",
    "\n",
    "with open(CORPUS_FILE, 'r', encoding='utf-8') as f:\n",
    "    corpus_dict = json.load(f)\n",
    "\n",
    "doc_ids = list(corpus_dict.keys())\n",
    "documents = list(corpus_dict.values())\n",
    "\n",
    "## Build sparse index\n",
    "\n",
    "def preprocess_text(text):\n",
    "    return re.sub(r'\\W+', ' ', text.lower()).split()\n",
    "\n",
    "stemmer = Stemmer('english')\n",
    "corpus_tokens = [stemmer.stemWords(preprocess_text(doc)) for doc in tqdm(documents)]\n",
    "\n",
    "retriever = bm25s.BM25()\n",
    "retriever.index(corpus_tokens)\n",
    "retriever.save(SPARSE_INDEX_PATH)\n",
    "\n",
    "## Build dense index\n",
    "\n",
    "model = SentenceTransformer(DENSE_MODEL)\n",
    "\n",
    "doc_embeddings = model.encode(documents, show_progress_bar=True, convert_to_numpy=True)\n",
    "doc_embeddings = doc_embeddings.astype('float32') # FAISS requires float32\n",
    "\n",
    "embedding_dim = doc_embeddings.shape[1]\n",
    "index = faiss.IndexFlatIP(embedding_dim)\n",
    "index.add(doc_embeddings)\n",
    "\n",
    "faiss.write_index(index, str(DENSE_INDEX_PATH))\n",
    "\n",
    "with open(DOC_IDS_PATH, 'w') as f:\n",
    "    json.dump(doc_ids, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d35570f",
   "metadata": {},
   "source": [
    "# Evidence Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4e9cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import bm25s\n",
    "from Stemmer import Stemmer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "## Configuration\n",
    "\n",
    "INDEX_DIR = Path(\"indexes\")\n",
    "SPARSE_INDEX_PATH = INDEX_DIR / \"bm25s_index\"\n",
    "DENSE_INDEX_PATH = INDEX_DIR / \"faiss_index.bin\"\n",
    "DOC_IDS_PATH = INDEX_DIR / \"doc_ids.json\"\n",
    "\n",
    "DATA_DIR = Path(\"data\")\n",
    "CLAIMS_FILE = DATA_DIR / \"final_decomposed_questions_list.csv\" \n",
    "CORPUS_FILE = DATA_DIR / \"corpus_evidence_unified.json\"\n",
    "\n",
    "OUTPUT_DIR = Path(\"output\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "RESULTS_FILE = OUTPUT_DIR / \"retrieval_results_top10.csv\"\n",
    "\n",
    "DENSE_MODEL = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "\n",
    "# NUM_CLAIMS_TO_PROCESS = len(pd.read_csv(CLAIMS_FILE)) \n",
    "NUM_CLAIMS_TO_PROCESS = 100 \n",
    "TOP_K = 10 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
